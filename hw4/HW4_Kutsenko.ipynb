{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt;padding-top:20px; text-align:center\">Домашнее задание 4. <b>Рекомендательные системы и Spark MLlib</b> </div><hr>\n",
    "<div style=\"text-align:right;\">Куценко А. А <span style=\"font-style: italic;font-weight: bold;\">(ftruf357ft@gmail.com)</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вариант\n",
    "eu_position = 8\n",
    "eu_position % 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Коллаборативная фильтрация\n",
    "\n",
    "- Вариант 1. По схожести пользователей\n",
    "- Вариант 2. По схожести объектов\n",
    "\n",
    "Этапы:\n",
    "1. Разделите данные с рейтингами на обучающее (train_init - 0.8) и тестовое подмножества (test - 0.2), определите среднее значение рейтинга в обучающем подмножестве и вычислите `rmse` для тестового подмножества, если для всех значений из test предсказывается среднее значение рейтинга\n",
    "2. Реализуйте коллаборативную фильтрацию в соответствии с вариантом. Для определения схожести используйте train_init, для расчета `rmse` - test\n",
    "3. Определите `rmse` для тестового подмножества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Подключение библиотек и создание Spark контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"]=\"/home/ubuntu/BigData/spark\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/home/ubuntu/ML/anaconda3/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/home/ubuntu/ML/anaconda3/bin/python\"\n",
    "\n",
    "spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python\"))\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python/lib/py4j-0.10.7-src.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf() \\\n",
    "        .setAppName(\"moviewRecomApp\") \\\n",
    "        .setMaster(\"local[16]\") \\\n",
    "        .set(\"spark.executor.memory\", \"16g\") \\\n",
    "        .set(\"spark.executor.core\", \"4\") \\\n",
    "        .set(\"spark.driver.memory\", \"32g\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://linux:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[16]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>moviewRecomApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f650c37d668>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных, разделение на обучающее и тестовое множество, расчет метрики базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdataset\u001b[00m\n",
      "├── \u001b[01;34mml-latest\u001b[00m\n",
      "│   ├── genome-scores.csv\n",
      "│   ├── genome-tags.csv\n",
      "│   ├── links.csv\n",
      "│   ├── movies.csv\n",
      "│   ├── ratings.csv\n",
      "│   ├── README.txt\n",
      "│   └── tags.csv\n",
      "└── \u001b[01;34mml-latest-small\u001b[00m\n",
      "    ├── links.csv\n",
      "    ├── movies.csv\n",
      "    ├── ratings.csv\n",
      "    ├── README.txt\n",
      "    └── tags.csv\n",
      "\n",
      "2 directories, 12 files\n",
      "-rw-r--r-- 1 ubuntu ubuntu 2.4M Sep 26  2018 dataset/ml-latest-small/ratings.csv\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 891M Jul 20  2023 dataset/ml-latest/ratings.csv\n"
     ]
    }
   ],
   "source": [
    "#!sudo apt install tree\n",
    "!tree dataset\n",
    "!ls -lah dataset/ml-latest-small/ratings.csv\n",
    "!ls -lah dataset/ml-latest/ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем в HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir -p /data/recom/small\n",
    "!hdfs dfs -mkdir -p /data/recom/large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/data/recom/small/ratings.csv': File exists\n",
      "copyFromLocal: `/data/recom/large/ratings.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -copyFromLocal /home/ubuntu/Documents/BigDataHWs/hw4/dataset/ml-latest-small/ratings.csv  /data/recom/small/ratings.csv\n",
    "!hdfs dfs -copyFromLocal /home/ubuntu/Documents/BigDataHWs/hw4/dataset/ml-latest/ratings.csv  /data/recom/large/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 ubuntu supergroup    482.8 K 2025-12-08 18:42 /data/recom/small/movies.csv\n",
      "-rw-r--r--   1 ubuntu supergroup      2.4 M 2025-12-08 18:43 /data/recom/small/ratings.csv\n",
      "Found 2 items\n",
      "-rw-r--r--   1 ubuntu supergroup      4.0 M 2025-12-08 19:01 /data/recom/large/movies.csv\n",
      "-rw-r--r--   1 ubuntu supergroup    890.6 M 2025-12-08 19:01 /data/recom/large/ratings.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -h /data/recom/small\n",
    "!hdfs dfs -ls -h /data/recom/large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доступ к данным из HDFS для небольшего набора данных\n",
    "ratings_data_small_path = \"hdfs:///data/recom/small/ratings.csv\"\n",
    "\n",
    "# Доступ к данным из HDFS для полного набора данных\n",
    "ratings_data_full_path = \"hdfs:///data/recom/large/ratings.csv\"\n",
    "\n",
    "RATINGS_FILE = ratings_data_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings = spark.read.load(RATINGS_FILE,\n",
    "                          format=\"csv\",\n",
    "                          header=\"true\",\n",
    "                          inferSchema=\"true\",\n",
    "                          sep=\",\")\n",
    "\n",
    "df_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "n_partitions = df_ratings.rdd.getNumPartitions()\n",
    "print(n_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = df_ratings.repartition(n_partitions * 4)\n",
    "df_ratings.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим данные на обучающее и тестовове подмножество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27065950, 6766212)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = df_ratings.randomSplit([0.8, 0.2], seed=12)\n",
    "df_train.persist().count(), df_test.persist().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний рейтинг фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.542462300418053"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_movie_rating = df_train.select(F.mean(\"rating\").alias(\"meanRating\")).collect()[0][\"meanRating\"]\n",
    "mean_movie_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование базовой модели. Всегда предсказываем среднее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     5|   3185|   4.0|1029389203|\n",
      "|    10|  91529|   4.5|1430667372|\n",
      "|    14|    260|   4.5|1311532965|\n",
      "|    21|    173|   1.0|1172766335|\n",
      "|    22| 106100|   5.0|1536154114|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-----------------+\n",
      "|userId|movieId|rating| timestamp|       prediction|\n",
      "+------+-------+------+----------+-----------------+\n",
      "|     5|   3185|   4.0|1029389203|3.542462300418053|\n",
      "|    10|  91529|   4.5|1430667372|3.542462300418053|\n",
      "|    14|    260|   4.5|1311532965|3.542462300418053|\n",
      "|    21|    173|   1.0|1172766335|3.542462300418053|\n",
      "|    22| 106100|   5.0|1536154114|3.542462300418053|\n",
      "+------+-------+------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_pred_bl = df_test.withColumn(\"prediction\", F.lit(mean_movie_rating))\n",
    "df_test_pred_bl.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем RMSE на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0638966156054195"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "eval_rmse.evaluate(df_test_pred_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Коллаборативная фильтрация на основе схожести объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/ubuntu/Documents/BigDataHWs/hw4/lib/recommend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itemrecom import ItemBasedRecommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based = ItemBasedRecommend(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itemrecom.ItemBasedRecommend at 0x7f64eb46f630>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_based.train(df_train, user_column_name=\"userId\", item_column_name=\"movieId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Предсказание**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = 123\n",
    "MOVIE_ID = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а) Предсказываем рейтинг одного фильма для одного пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.674583682536866"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_based.predict_single(USER, MOVIE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "б) Список рекомендаций для пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_RATINGS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+----+\n",
      "|item|      rating_pred|user|\n",
      "+----+-----------------+----+\n",
      "| 728|5.000000000000001| 123|\n",
      "| 905|5.000000000000001| 123|\n",
      "| 931|5.000000000000001| 123|\n",
      "| 948|5.000000000000001| 123|\n",
      "| 971|5.000000000000001| 123|\n",
      "|1237|5.000000000000001| 123|\n",
      "|1401|5.000000000000001| 123|\n",
      "|1939|5.000000000000001| 123|\n",
      "|2142|5.000000000000001| 123|\n",
      "|2203|5.000000000000001| 123|\n",
      "|2204|5.000000000000001| 123|\n",
      "|2772|5.000000000000001| 123|\n",
      "|2922|5.000000000000001| 123|\n",
      "|3089|5.000000000000001| 123|\n",
      "|3549|5.000000000000001| 123|\n",
      "|4406|5.000000000000001| 123|\n",
      "|4498|5.000000000000001| 123|\n",
      "|4591|5.000000000000001| 123|\n",
      "| 949|5.000000000000001| 123|\n",
      "|5008|5.000000000000001| 123|\n",
      "+----+-----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_recom = item_based.recommend(user_ids=[USER], top_N_ratings=TOP_N_RATINGS, grouped=False, partition_num=128)\n",
    "df_recom.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных пользователей:  305858\n"
     ]
    }
   ],
   "source": [
    "# Все уникальные пользователи в тестовом множестве\n",
    "U = {el[\"userId\"] for el in df_test[[F.col(\"userId\")]].distinct().collect()}\n",
    "\n",
    "print(\"Уникальных пользователей: \", len(U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------------------+\n",
      "|  user|item|       rating_pred|\n",
      "+------+----+------------------+\n",
      "|321627|1127| 4.250301020732027|\n",
      "|190539| 519|2.9732897467170822|\n",
      "|266231| 379| 2.992421703265427|\n",
      "|280494|1676| 3.947523170882441|\n",
      "|104306|1544|3.7224053484299247|\n",
      "| 42068|1690| 3.139618461925116|\n",
      "|158939|1127|  3.91853013198041|\n",
      "|244499|2455|3.1866146602406884|\n",
      "|323858|1544| 2.749598046925327|\n",
      "| 68214|2916|1.9463080822468228|\n",
      "|146375| 379|3.4999999999999996|\n",
      "|133664|1590| 3.871693654940541|\n",
      "|270155|3527|  2.97993385255655|\n",
      "| 77219|1255|  4.02487009301907|\n",
      "|195299|2455| 3.250749371198191|\n",
      "|188407| 379|3.5000000000000004|\n",
      "|284393|1573|1.2705593827044346|\n",
      "|292083|1391|3.5859818561238916|\n",
      "|205325|2985|3.8602270560144682|\n",
      "|309101| 849|3.3595999951504623|\n",
      "+------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_predicted = item_based.predict(df_test, user_column_name=\"userId\", item_column_name=\"movieId\")\n",
    "df_test_predicted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----+----+------------------+\n",
      "|userId|movieId|rating| timestamp|user|item|       rating_pred|\n",
      "+------+-------+------+----------+----+----+------------------+\n",
      "|    21|   3686|   5.0|1173150744|  21|3686|               2.0|\n",
      "|    24|    302|   4.5|1062938525|  24| 302|               4.0|\n",
      "|    24|   3624|   3.5|1062939808|  24|3624|3.6132913846775274|\n",
      "|    53|   2997|   4.0|1134596942|  53|2997| 4.034656831669875|\n",
      "|    53|   7361|   4.5|1134596041|  53|7361| 3.840828356121518|\n",
      "+------+-------+------+----------+----+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_true_pred = df_test.join(df_test_predicted, on=[(F.col(\"userId\")==F.col(\"user\")), \n",
    "                                                   (F.col(\"movieId\")==F.col(\"item\"))])\n",
    "df_true_pred.persist(StorageLevel.MEMORY_ONLY).count()\n",
    "df_true_pred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true_pred.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443230507480239"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"rating_pred\")\n",
    "eval_rmse.evaluate(df_true_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
